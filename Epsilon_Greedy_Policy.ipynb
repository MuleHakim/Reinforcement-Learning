{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbIltjpCxW7trp40YVvCoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuleHakim/Reinforcement-Learning/blob/main/Epsilon_Greedy_Policy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Epsilon-Greedy Policy"
      ],
      "metadata": {
        "id": "cx_Jp7UxVEKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid World (FrozenLake Environment)\n"
      ],
      "metadata": {
        "id": "Qviu-baUVF69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfLlglSxU5fN",
        "outputId": "391b03ce-5831-4a5a-b94d-298f5088e106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "H0dZ4piKVKy_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the FrozenLake environment\n",
        "env = gym.make('FrozenLake-v1', is_slippery=False)"
      ],
      "metadata": {
        "id": "TQTk1WqCWtGO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Q-table with zeros\n",
        "q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "# q_table = np.random.rand(env.observation_space.n, env.action_space.n)\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.99  # Discount factor\n",
        "epsilon = 0.5  # Exploration rate\n",
        "num_episodes = 50000\n",
        "max_steps = 100"
      ],
      "metadata": {
        "id": "2WSguLRuWUqP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the agent using epsilon-greedy policy\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    for step in range(max_steps):\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(q_table[state, :])\n",
        "\n",
        "        new_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        q_table[state, action] = q_table[state, action] + alpha * (\n",
        "                    reward + gamma * np.max(q_table[new_state, :]) - q_table[state, action])\n",
        "\n",
        "        state = new_state\n",
        "\n",
        "        if done:\n",
        "            break"
      ],
      "metadata": {
        "id": "5NIUpaXrWSFu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Q-Table using Epsilon-Greedy:\", q_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvKPdsg_VMRc",
        "outputId": "c7905d60-7b02-4741-eb40-cb822f09755f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Table using Epsilon-Greedy: [[0.94148015 0.95099005 0.95099005 0.94148015]\n",
            " [0.94148015 0.         0.96059601 0.95099005]\n",
            " [0.95099005 0.970299   0.95099005 0.96059601]\n",
            " [0.96059601 0.         0.95099005 0.95099005]\n",
            " [0.95099005 0.96059601 0.         0.94148015]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.9801     0.         0.96059601]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.96059601 0.         0.970299   0.95099005]\n",
            " [0.96059601 0.9801     0.9801     0.        ]\n",
            " [0.970299   0.99       0.         0.970299  ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.9801     0.99       0.970299  ]\n",
            " [0.9801     0.99       1.         0.9801    ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jfu3ghVJa6Wm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CcSPxUgWcCxX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single-State Multi-Armed Bandit\n"
      ],
      "metadata": {
        "id": "fmb8yc9VcDbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 10  # Number of arms\n",
        "q_table = np.zeros(k)\n",
        "alpha = 0.1  # Learning rate\n",
        "gamma = 0.99  # Discount factor\n",
        "epsilon = 0.1  # Exploration rate\n",
        "num_steps = 1000"
      ],
      "metadata": {
        "id": "ScK4bk-qcMZ5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate the epsilon-greedy policy\n",
        "for step in range(num_steps):\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "        action = random.randint(0, k-1)\n",
        "    else:\n",
        "        action = np.argmax(q_table)\n",
        "\n",
        "    reward = np.random.normal(action, 1.0)  # Assume normal distribution with unit variance\n",
        "\n",
        "    q_table[action] = q_table[action] + alpha * (reward + gamma * np.max(q_table) - q_table[action])"
      ],
      "metadata": {
        "id": "nYrrXUk3cOAU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Q-Table using Epsilon-Greedy for Bandit:\", q_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DsWZpHQcP8v",
        "outputId": "3ddd3d28-8a98-40b5-b913-13281c6e414c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Table using Epsilon-Greedy for Bandit: [ 83.40575822  89.14516235  94.61767988  84.43182954 236.50320981\n",
            " 107.77731379 117.39320702 135.7021066   55.74063539 118.81586401]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HjumDZhOcSNd"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}